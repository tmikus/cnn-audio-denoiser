{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b25b5480",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a29f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import scipy\n",
    "import soundfile as sf\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43ddb395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audio(filepath, sample_rate, normalize=True):\n",
    "    \"\"\"Read an audio file and return it as a numpy array\"\"\"\n",
    "    audio, sr = librosa.load(filepath, sr=sample_rate)\n",
    "    if normalize:\n",
    "      div_fac = 1 / np.max(np.abs(audio)) / 3.0\n",
    "      audio = audio * div_fac\n",
    "    return audio, sr\n",
    "\n",
    "def revert_features_to_audio(features, phase, cleanMean=None, cleanStd=None):\n",
    "    # scale the outpus back to the original range\n",
    "    if cleanMean and cleanStd:\n",
    "        features = cleanStd * features + cleanMean\n",
    "\n",
    "    phase = np.transpose(phase, (1, 0))\n",
    "    features = np.squeeze(features)\n",
    "\n",
    "    # features = librosa.db_to_power(features)\n",
    "    features = features * np.exp(1j * phase)  # that fixes the abs() ope previously done\n",
    "\n",
    "    features = np.transpose(features, (1, 0))\n",
    "    return noiseAudioFeatureExtractor.get_audio_from_stft_spectrogram(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8db6342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self, audio, *, windowLength, overlap, sample_rate):\n",
    "        self.audio = audio\n",
    "        self.ffT_length = windowLength\n",
    "        self.window_length = windowLength\n",
    "        self.overlap = overlap\n",
    "        self.sample_rate = sample_rate\n",
    "        self.window = scipy.signal.hamming(self.window_length, sym=False)\n",
    "\n",
    "    def get_stft_spectrogram(self):\n",
    "        return librosa.stft(self.audio, n_fft=self.ffT_length, win_length=self.window_length, hop_length=self.overlap,\n",
    "                            window=self.window, center=True)\n",
    "\n",
    "    def get_audio_from_stft_spectrogram(self, stft_features):\n",
    "        return librosa.istft(stft_features, win_length=self.window_length, hop_length=self.overlap,\n",
    "                             window=self.window, center=True)\n",
    "\n",
    "    def get_mel_spectrogram(self):\n",
    "        return librosa.feature.melspectrogram(self.audio, sr=self.sample_rate, power=2.0, pad_mode='reflect',\n",
    "                                           n_fft=self.ffT_length, hop_length=self.overlap, center=True)\n",
    "\n",
    "    def get_audio_from_mel_spectrogram(self, M):\n",
    "        return librosa.feature.inverse.mel_to_audio(M, sr=self.sample_rate, n_fft=self.ffT_length, hop_length=self.overlap,\n",
    "                                             win_length=self.window_length, window=self.window,\n",
    "                                             center=True, pad_mode='reflect', power=2.0, n_iter=32, length=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ad7feb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numSegments  = 8\n",
    "numFeatures  = windowLength // 2 + 1\n",
    "\n",
    "def prepare_input_features(stft_features):\n",
    "    # Phase Aware Scaling: To avoid extreme differences (more than\n",
    "    # 45 degree) between the noisy and clean phase, the clean spectral magnitude was encoded as similar to [21]:\n",
    "    noisySTFT = np.concatenate([stft_features[:,0:numSegments-1], stft_features], axis=1)\n",
    "    stftSegments = np.zeros((numFeatures, numSegments , noisySTFT.shape[1] - numSegments + 1))\n",
    "\n",
    "    for index in range(noisySTFT.shape[1] - numSegments + 1):\n",
    "        stftSegments[:,:,index] = noisySTFT[:,index:index + numSegments]\n",
    "    return stftSegments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9d7c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowLength = 256\n",
    "overlap      = round(0.25 * windowLength) # overlap of 75%\n",
    "model = load_model(\"denoiser_cnn_log_mel_generator.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b90b5b",
   "metadata": {},
   "source": [
    "# Noise Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3da1dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = \"./buran_16.wav\"\n",
    "output_file_path = \"./buran_denoised.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6dbd756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 16000\n",
    "noisyAudio, sr = read_audio(input_file_path, sample_rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "679d09bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 196941)\n"
     ]
    }
   ],
   "source": [
    "noiseAudioFeatureExtractor = FeatureExtractor(noisyAudio, windowLength=windowLength, overlap=overlap, sample_rate=sr)\n",
    "noise_stft_features = noiseAudioFeatureExtractor.get_stft_spectrogram()\n",
    "\n",
    "# Paper: Besides, spectral phase was not used in the training phase.\n",
    "# At reconstruction, noisy spectral phase was used instead to\n",
    "# perform in- verse STFT and recover human speech.\n",
    "noisyPhase = np.angle(noise_stft_features)\n",
    "print(noisyPhase.shape)\n",
    "noise_stft_features = np.abs(noise_stft_features)\n",
    "\n",
    "mean = np.mean(noise_stft_features)\n",
    "std = np.std(noise_stft_features)\n",
    "noise_stft_features = (noise_stft_features - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "333a533b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictors.shape: (196941, 129, 8, 1)\n"
     ]
    }
   ],
   "source": [
    "predictors = prepare_input_features(noise_stft_features)\n",
    "predictors = np.reshape(predictors, (predictors.shape[0], predictors.shape[1], 1, predictors.shape[2]))\n",
    "predictors = np.transpose(predictors, (3, 0, 1, 2)).astype(np.float32)\n",
    "print('predictors.shape:', predictors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de45d0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196941, 129, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "STFTFullyConvolutional = model.predict(predictors)\n",
    "print(STFTFullyConvolutional.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46c449fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: -0.17460601 Max: 0.24059172\n"
     ]
    }
   ],
   "source": [
    "denoisedAudioFullyConvolutional = revert_features_to_audio(STFTFullyConvolutional, noisyPhase, mean, std)\n",
    "print(\"Min:\", np.min(denoisedAudioFullyConvolutional),\"Max:\",np.max(denoisedAudioFullyConvolutional))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a3b59ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write(output_file_path, denoisedAudioFullyConvolutional, 16000, subtype=\"PCM_16\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
